# Introduction To Knative

> In this chapter, you'll learn about Knative and how to install the Knative Serving component.

Serverless computing is a development model that allows developers to build and run applications without having to manage servers. It describes a model where a _cloud_ provider handles the routine work of provisioning, maintaining, and scaling the server infrastructure, while the developers can simply package and upload their code for deployment. Serverless apps can automatically scale up and down as needed, without any extra configuration by the developer.

As stated in a [whitepaper](https://github.com/cncf/wg-serverless/tree/master/whitepapers/serverless-overview) by the CNCF serverless working group, there are two primary serverless personas:

1. **Developer**: writes code for, and benefits from the serverless platform which provides them the point of view that there are no servers nor that their code is always running.

2. **Provider**: deploys the serverless platform for an external or internal customer.

The _provider_ will need to manage servers (or containers), and will have some cost for running the platform, even when idle. A self-hosted system can still be considered _serverless_: typically one team acts as the **provider** and another as the **developer**.

In the kubernetes landscape, there various ways to run serverless apps. It can be through managed serverless platforms like IBM Cloud Code, or open-source alternative that you can self-host (e.g OpenFaaS and Knative).

## Knative

Knative is a set of Kubernetes components that provides serverless capabilities. With Knative, you can build and run applications and services that can auto-scale based on demand, with out-of-the-box support for monitoring, automantic renewal of TLS certificates, and many more.

Knative is used by a lot of companies, it in fact powers the Google Cloud Run platform, and also IBM Cloud Code.

The basic deployment unit for Knative is a container that can receive incoming traffic. You give it a container image to run and Knative handles every other component needed to run and scale the application. The deployment and management of the containerized app is handled by one of the core components of Knative, called **Knative Serving**. Knative Serving is the component in Knative that manages the deployment and rollout of stateless services, its networking and autoscaling requirements.

The other core component of Knative is called **Knative Eventing**. This component provides an abstract way to consume events from from internal and external sources, without writng extra code for different event sources. We'll talk more on the various use-cases later.

## Creating A Kubernetes Cluster

You will need a Kubernetes cluster to run Knative. You're going to work with a local Kubernetes cluster running on Docker. You should have Docker Desktop installed. If not you can download and install it using this [link](https://docs.docker.com/get-docker/).

### Create cluster with Docker Desktop

Docker Desktop includes a standalone Kubernetes server and client. This is a single-node cluster that runs within a Docker container on your local system, and should be used only for local testing. The Kubernetes client command `kubectl` is included with the installation.

To enable Kubernetes support and install a standalone instance of Kubernetes running as a Docker container, follow the instructions on this [page](https://docs.docker.com/desktop/kubernetes/#enable-kubernetes).

### Alternatively, Create a cluster with kind

You can also create a cluster using [kind](https://kind.sigs.k8s.io/), a tool for running local Kubernetes clusters using Docker container _nodes_. If you have kind installed, you can run the command below to create your kind cluster and set the `kubectl` context.

```bash
curl -sL https://raw.githubusercontent.com/csantanapr/knative-kind/master/01-kind.sh | sh
```

## Install Knative Serving

Knative will manage your application/serviceâ€™s deployments, revisions, networking, and scaling. The Knative Serving component exposes your service via an HTTP URL and has safe defaults for its configurations. To install the Serving componnent, run the following script.

```bash
curl -sL https://raw.githubusercontent.com/csantanapr/knative-kind/master/02-serving.sh | sh
```

This installs the Serving component, a networking layer (Kourier), and configured the DNS. The domain that is configured for use is `nip.io`.

You can find out more about what that script does on [konk.dev](konk.dev), specifically on this [URL](https://github.com/csantanapr/knative-kind#install-knative-serving).
